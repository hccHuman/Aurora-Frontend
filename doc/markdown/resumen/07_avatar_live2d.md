# ðŸ¤– Avatar Virtual Live2D

## VisiÃ³n General

El **avatar Haru** es el corazÃ³n visual de Aurora. Es un modelo **Live2D Cubism v4.2.4** renderizado con **PIXI.js**, capaz de expresar emociones, hablar y moverse naturalmente.

## CaracterÃ­sticas del Avatar

| Aspecto | DescripciÃ³n |
|--------|-------------|
| **Nombre** | Haru (æ˜¥ - Primavera) |
| **GÃ©nero** | Femenino |
| **Estilo** | Anime chibi-realista |
| **Formato** | Live2D Cubism 4.2.4 |
| **Motor Render** | PIXI.js 6.5.8 |
| **ResoluciÃ³n** | Escalable (adaptativa) |

## Estructura de Archivos

```
public/models/haru/
â”œâ”€â”€ haru_greeter_t05.model3.json     # Archivo modelo principal
â”œâ”€â”€ haru_greeter_t05.physics3.json   # FÃ­sica (movimiento natural)
â”œâ”€â”€ haru_greeter_t05.userdata3.json  # Datos del usuario
â”‚
â”œâ”€â”€ runtime/
â”‚   â”œâ”€â”€ haru_greeter_t05.cmo3        # Estructura 3D compilada
â”‚   â”‚
â”‚   â”œâ”€â”€ expressions/                  # 8 expresiones faciales
â”‚   â”‚   â”œâ”€â”€ Angry.exp3.json          # Enfadado
â”‚   â”‚   â”œâ”€â”€ Doubt.exp3.json          # Dudoso
â”‚   â”‚   â”œâ”€â”€ Happy.exp3.json          # Feliz
â”‚   â”‚   â”œâ”€â”€ Neutral.exp3.json        # Neutral
â”‚   â”‚   â”œâ”€â”€ Sad.exp3.json            # Triste
â”‚   â”‚   â”œâ”€â”€ Smile.exp3.json          # Sonrisa
â”‚   â”‚   â”œâ”€â”€ Surprised.exp3.json      # Sorprendido
â”‚   â”‚   â””â”€â”€ Worried.exp3.json        # Preocupado
â”‚   â”‚
â”‚   â”œâ”€â”€ motion/                       # ~20 animaciones corporales
â”‚   â”‚   â”œâ”€â”€ haru_g_idle.motion3.json         # Reposo (default)
â”‚   â”‚   â”œâ”€â”€ haru_g_m01.motion3.json         # Saludo
â”‚   â”‚   â”œâ”€â”€ haru_g_m02.motion3.json         # Sonrisa/celebraciÃ³n
â”‚   â”‚   â”œâ”€â”€ haru_g_m03.motion3.json         # Pensamiento
â”‚   â”‚   â”œâ”€â”€ haru_g_m04.motion3.json         # Sorpresa
â”‚   â”‚   â”œâ”€â”€ haru_g_m05.motion3.json         # Gesto explicativo
â”‚   â”‚   â”œâ”€â”€ haru_g_m06.motion3.json         # Asentimiento
â”‚   â”‚   â”œâ”€â”€ haru_g_m07.motion3.json         # NegaciÃ³n
â”‚   â”‚   â”œâ”€â”€ haru_g_m08.motion3.json         # Tristeza
â”‚   â”‚   â””â”€â”€ ...mÃ¡s motions
â”‚   â”‚
â”‚   â”œâ”€â”€ textures/                    # Texturas del modelo
â”‚   â”‚   â”œâ”€â”€ haru_greeter_t05.2048/
â”‚   â”‚   â”‚   â”œâ”€â”€ haru_body_01.png
â”‚   â”‚   â”‚   â”œâ”€â”€ haru_face_01.png
â”‚   â”‚   â”‚   â”œâ”€â”€ haru_hair_01.png
â”‚   â”‚   â”‚   â”œâ”€â”€ haru_eyes_01.png
â”‚   â”‚   â”‚   â””â”€â”€ ...mÃ¡s texturas
â”‚   â”‚   â””â”€â”€ haru_greeter_t05.1024/  # VersiÃ³n optimizada
â”‚   â”‚
â”‚   â””â”€â”€ sounds/                      # Sonidos (opcional)
â”‚       â””â”€â”€ ... audio files
â”‚
â””â”€â”€ physics/
    â””â”€â”€ haru_greeter_t05.physics3.json
```

## Componente VtuberLive2D.tsx

```typescript
// UbicaciÃ³n: src/modules/AURORA/components/VtuberLive2D.tsx

import { useEffect, useRef, useState } from 'react';
import * as PIXI from 'pixi.js';
import { Live2DModel } from 'pixi-live2d-display';
import { AuroraVoiceLocal } from '@/modules/AURORA/core/AuroraVoice';

export interface VtuberLive2DProps {
  className?: string;
  modelPath?: string;
}

export function VtuberLive2D({
  className = '',
  modelPath = '/models/haru/haru_greeter_t05.model3.json'
}: VtuberLive2DProps) {
  
  const canvasRef = useRef<HTMLDivElement>(null);
  const appRef = useRef<PIXI.Application | null>(null);
  const modelRef = useRef<Live2DModel | null>(null);
  const [voiceInstance, setVoiceInstance] = useState<AuroraVoiceLocal | null>(null);
  
  useEffect(() => {
    // 1. Detectar idioma de URL
    const pathLang = window.location.pathname.includes("/en/") ? "en" : "es";
    
    // 2. Crear instancia de voz si no existe
    if (!voiceInstance) {
      const newVoice = new AuroraVoiceLocal(pathLang);
      setVoiceInstance(newVoice);
    } else {
      // 3. Cambiar idioma si cambiÃ³ la URL
      if (voiceInstance.currentLang !== pathLang) {
        voiceInstance.setLanguage(pathLang);
      }
    }
  }, [voiceInstance]);
  
  useEffect(() => {
    if (!canvasRef.current) return;
    
    // Inicializar PIXI
    const initPixi = async () => {
      try {
        // Crear aplicaciÃ³n PIXI
        const app = new PIXI.Application({
          view: undefined,
          resolution: window.devicePixelRatio,
          autoDensity: true,
          backgroundColor: 0xffffff,
          width: canvasRef.current!.clientWidth,
          height: canvasRef.current!.clientHeight
        });
        
        canvasRef.current.appendChild(app.view as HTMLCanvasElement);
        appRef.current = app;
        
        // Cargar modelo Live2D
        const model = await Live2DModel.from(modelPath);
        modelRef.current = model;
        
        // Configurar modelo
        model.scale.set(0.28);
        model.x = app.view.width * 0.5;
        model.y = app.view.height * 0.5;
        
        app.stage.addChild(model);
        
        // Registrar ticker
        Live2DModel.registerTicker(PIXI.Ticker.shared);
        
      } catch (error) {
        console.error('Error initializing avatar:', error);
      }
    };
    
    initPixi();
    
    // Cleanup
    return () => {
      if (appRef.current) {
        appRef.current.destroy();
      }
    };
  }, [modelPath]);
  
  // MÃ©todos pÃºblicos para control
  const playExpression = (expression: string) => {
    if (modelRef.current) {
      const url = `/models/haru/runtime/expressions/${expression}.exp3.json`;
      modelRef.current.expression?.setExpression(url);
    }
  };
  
  const playMotion = (motion: string, group = 'motion') => {
    if (modelRef.current) {
      const url = `/models/haru/runtime/motion/${motion}.motion3.json`;
      modelRef.current.motion?.startMotion(url, group, 4);
    }
  };
  
  return (
    <div 
      ref={canvasRef} 
      className={`w-full h-full bg-white rounded-lg shadow-lg ${className}`}
    />
  );
}

export default VtuberLive2D;
```

## Sistema de Lip-Sync (SincronizaciÃ³n Labial)

```typescript
// UbicaciÃ³n: src/modules/AURORA/core/AuroraVoice.ts

public emitLipSyncEvents(text: string): void {
  // Estimar duraciÃ³n basada en caracteres
  const estimatedDuration = Math.max(2000, text.length * 50);
  
  // Emitir eventos de lip-sync cada 50ms
  let elapsed = 0;
  const interval = setInterval(() => {
    if (elapsed >= estimatedDuration) {
      clearInterval(interval);
      return;
    }
    
    // Generar valor de apertura de boca (0-1)
    const mouthOpenValue = Math.sin(elapsed / 100) * 0.5 + 0.5;
    
    // Emitir evento global
    window.dispatchEvent(new CustomEvent('aurora-lipsync', {
      detail: { value: mouthOpenValue }
    }));
    
    elapsed += 50;
  }, 50);
}
```

## Mapeo de Emociones a Animaciones

```typescript
// Mapeo completo de emociones
const EMOTION_ANIMATIONS = {
  happy: {
    expression: 'Happy.exp3.json',
    motion: 'haru_g_m02.motion3.json',
    description: 'Sonrisa amplia con movimiento de celebraciÃ³n'
  },
  
  sad: {
    expression: 'Sad.exp3.json',
    motion: 'haru_g_m08.motion3.json',
    description: 'ExpresiÃ³n triste con movimiento de consuelo'
  },
  
  surprised: {
    expression: 'Surprised.exp3.json',
    motion: 'haru_g_m04.motion3.json',
    description: 'Ojos abiertos, boca sorprendida'
  },
  
  neutral: {
    expression: 'Neutral.exp3.json',
    motion: 'haru_g_idle.motion3.json',
    description: 'PosiciÃ³n por defecto'
  },
  
  angry: {
    expression: 'Angry.exp3.json',
    motion: 'haru_g_m05.motion3.json',
    description: 'Cejas fruncidas, movimiento enÃ©rgico'
  },
  
  worried: {
    expression: 'Worried.exp3.json',
    motion: 'haru_g_m03.motion3.json',
    description: 'ExpresiÃ³n preocupada'
  }
};
```

## ParÃ¡metros Animables del Modelo

El modelo Live2D expone parÃ¡metros que pueden ser controlados:

```
ParamMouthOpenY      # Apertura vertical de la boca
ParamMouthOpen       # Apertura general de la boca
ParamMouthOpenX      # Apertura horizontal
ParamEyeLOpen        # Apertura ojo izquierdo
ParamEyeROpen        # Apertura ojo derecho
ParamBrowLY          # Altura ceja izquierda
ParamBrowRY          # Altura ceja derecha
ParamEyeBallX        # DirecciÃ³n horizontal mirada
ParamEyeBallY        # DirecciÃ³n vertical mirada
ParamBodyAngleX      # RotaciÃ³n cabeza X
ParamBodyAngleY      # RotaciÃ³n cabeza Y
ParamBodyAngleZ      # RotaciÃ³n cabeza Z
```

## AdaptaciÃ³n por Dispositivo

```typescript
const getAvatarConfig = (device: 'desktop' | 'tablet' | 'mobile') => {
  switch(device) {
    case 'desktop':
      return {
        scale: 0.28,
        positionX: 0.5,
        positionY: 0.45,
        clipHeight: 'none'  // Sin clipping
      };
    
    case 'tablet':
      return {
        scale: 0.22,
        positionX: 0.5,
        positionY: 0.40,
        clipHeight: 'none'
      };
    
    case 'mobile':
      return {
        scale: 0.18,
        positionX: 0.5,
        positionY: 0.35,
        clipHeight: '600px'  // Clipping para no tapar chat
      };
  }
};
```

## Evento de Persistencia (astro:after-swap)

```typescript
// Cuando el usuario navega sin recargar (SPA)
document.addEventListener('astro:after-swap', () => {
  // El avatar persiste automÃ¡ticamente
  // Solo reinicializar listeners si es necesario
  
  const pathLang = window.location.pathname.includes("/en/") ? "en" : "es";
  if (voiceRef.current && voiceRef.current.currentLang !== pathLang) {
    voiceRef.current.setLanguage(pathLang);
  }
});
```

## Ejemplo de Uso Completo

```typescript
// En VtuberLive2D.tsx
const avatarRef = useRef();

// Aplicar instrucciÃ³n del avatar
const applyAuroraInstruction = (instruction: AuroraInstruction) => {
  if (!avatarRef.current) return;
  
  // Aplicar expresiÃ³n
  avatarRef.current.playExpression(instruction.expression);
  
  // Aplicar movimiento
  setTimeout(() => {
    avatarRef.current.playMotion(instruction.motion);
  }, 100);
  
  // Reproducir voz
  if (instruction.text) {
    voiceInstance.speak(instruction.text);
  }
};

// Llamar cuando haya nueva instrucciÃ³n
useEffect(() => {
  if (currentInstruction) {
    applyAuroraInstruction(currentInstruction);
  }
}, [currentInstruction]);
```

## Performance Optimization

```typescript
// Mipmap para texturas (mejor rendimiento en zoom)
const mipmapSettings = {
  minFilter: PIXI.SCALE_MODES.LINEAR,
  magFilter: PIXI.SCALE_MODES.LINEAR,
  mipmap: true
};

// Usar WebGL con fallback Canvas
const app = new PIXI.Application({
  preference: 'webgl',
  antialias: true,
  ...mipmapSettings
});

// Reducir ticker si estÃ¡ fuera de pantalla
if (document.hidden) {
  PIXI.Ticker.shared.speed = 0;
} else {
  PIXI.Ticker.shared.speed = 1;
}
```

## Debugging del Avatar

```typescript
// Log de parÃ¡metros detectados
const logDetectedParameters = (model: Live2DModel) => {
  const params = model.internalModel.parameters;
  console.log('Detected parameters:', params.map(p => p.id));
};

// Probar expresiÃ³n
window.testExpression = (name: string) => {
  avatarRef.current?.playExpression(name);
};

// Probar movimiento
window.testMotion = (name: string) => {
  avatarRef.current?.playMotion(name);
};

// En consola: testExpression('Happy'), testMotion('haru_g_m02')
```

## Propiedades en Vivo del Avatar

El avatar es **responsive** a:
- âœ… Cambios de emociÃ³n
- âœ… Entrada de usuario
- âœ… Respuesta del backend
- âœ… Cambio de idioma
- âœ… NavegaciÃ³n entre pÃ¡ginas (SPA)
- âœ… TamaÃ±o de pantalla

---

**Ãšltima actualizaciÃ³n**: Enero 2026  
**Modelo**: Haru Greeter T05  
**SDK**: Live2D Cubism 4.2.4
